{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06b124b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-19 10:08:23.582\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdsci_utilities.BQHelper\u001b[0m:\u001b[36mget_string\u001b[0m:\u001b[36m328\u001b[0m - \u001b[1mRunning string: \n",
      "    SELECT\n",
      "      ANY_VALUE(l.model_name) AS model_name,\n",
      "      ANY_VALUE(l.primary_category) AS primary_category,\n",
      "      ANY_VALUE(l.secondary_category) AS secondary_category,\n",
      "      ANY_VALUE(l.product_type) AS product_type,\n",
      "      ANY_VALUE(l.product_system) AS product_system,\n",
      "      ANY_VALUE(l.brand) AS brand,\n",
      "      ANY_VALUE(l.family) AS family,\n",
      "      SUM(h.units_traded) / 5 AS units_traded\n",
      "    FROM\n",
      "      `mpb-data-science-dev-ab-602d.dsci_pricing_model.pm_base_050_model_lu` l\n",
      "    JOIN\n",
      "      `mpb-data-science-dev-ab-602d.dsci_pricing_model.pm_optimiser_040_scenarios_trade_history` h\n",
      "    ON\n",
      "      l.model_id = h.model_id\n",
      "      AND l.market = h.market\n",
      "    WHERE\n",
      "      h.months_prior_to_current BETWEEN 1 AND 5\n",
      "      AND h.sale_direction = 'buy'\n",
      "    GROUP BY\n",
      "      l.model_name\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-19 10:08:26.142\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdsci_utilities.BQHelper\u001b[0m:\u001b[36m_run_query\u001b[0m:\u001b[36m214\u001b[0m - \u001b[1m\n",
      "\tDuration: 0.37 seconds\n",
      "\tData Processed: 0.04 GB\n",
      "\tData Billed: 0.04 GB\n",
      "Returned 994 rows, 8 columns\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame memory usage: 0.52 MB\n",
      "Estimated embedding matrix size: 1.53 MB\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from rapidfuzz import fuzz\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import faiss\n",
    "import re\n",
    "from dsci_utilities import BQHelper\n",
    "from difflib import SequenceMatcher\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "\n",
    "# GCP Configuration\n",
    "GOOGLE_CLOUD_PROJECT = \"mpb-data-science-dev-ab-602d\"\n",
    "GOOGLE_CLOUD_DATASET = \"dsci_pricing_model\"\n",
    "GOOGLE_CLOUD_LOCATION = \"us-central1\"\n",
    "GOOGLE_GENAI_USE_VERTEXAI = True\n",
    "MODEL = \"gemini-2.0-flash-001\"\n",
    "\n",
    "# BigQuery Helper\n",
    "bq = BQHelper(\n",
    "    billing_project_id=GOOGLE_CLOUD_PROJECT,\n",
    "    write_project_id=GOOGLE_CLOUD_PROJECT,\n",
    "    read_project_id=GOOGLE_CLOUD_PROJECT,\n",
    "    write_dataset=GOOGLE_CLOUD_DATASET,\n",
    "    read_dataset=GOOGLE_CLOUD_DATASET,\n",
    "    daw_dataset=GOOGLE_CLOUD_DATASET,\n",
    "    sql_folder=\"\",\n",
    ")\n",
    "\n",
    "# Load data from BigQuery\n",
    "df_in = bq.get_string(\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "      ANY_VALUE(l.model_name) AS model_name,\n",
    "      ANY_VALUE(l.primary_category) AS primary_category,\n",
    "      ANY_VALUE(l.secondary_category) AS secondary_category,\n",
    "      ANY_VALUE(l.product_type) AS product_type,\n",
    "      ANY_VALUE(l.product_system) AS product_system,\n",
    "      ANY_VALUE(l.brand) AS brand,\n",
    "      ANY_VALUE(l.family) AS family,\n",
    "      SUM(h.units_traded) / 5 AS units_traded\n",
    "    FROM\n",
    "      `mpb-data-science-dev-ab-602d.dsci_pricing_model.pm_base_050_model_lu` l\n",
    "    JOIN\n",
    "      `mpb-data-science-dev-ab-602d.dsci_pricing_model.pm_optimiser_040_scenarios_trade_history` h\n",
    "    ON\n",
    "      l.model_id = h.model_id\n",
    "      AND l.market = h.market\n",
    "    WHERE\n",
    "      h.months_prior_to_current BETWEEN 1 AND 5\n",
    "      AND h.sale_direction = 'buy'\n",
    "    GROUP BY\n",
    "      l.model_name\n",
    "    \"\"\",\n",
    "    silent=True,\n",
    ")\n",
    "\n",
    "# Prepare DataFrame\n",
    "df = df_in.copy()\n",
    "mem_usage_mb = df.memory_usage(deep=True).sum() / 1e6\n",
    "print(f\"DataFrame memory usage: {mem_usage_mb:.2f} MB\")\n",
    "n_rows = len(df)\n",
    "embedding_dim = 384\n",
    "embedding_bytes = n_rows * embedding_dim * 4  # float32 = 4 bytes\n",
    "embedding_mb = embedding_bytes / 1e6\n",
    "\n",
    "print(f\"Estimated embedding matrix size: {embedding_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8912d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define noise words\n",
    "NOISE_WORDS = set(\n",
    "    [\n",
    "        \"camera\",\n",
    "        \"cameras\",\n",
    "        \"cam\",\n",
    "        \"product\",\n",
    "        \"category\",\n",
    "        \"brand\",\n",
    "        \"family\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Load resources\n",
    "def load_resources():\n",
    "    print(\"Loading dense encoder...\")\n",
    "    dense_model = SentenceTransformer(\"all-mpnet-base-v2\", device=\"cpu\")\n",
    "    return dense_model\n",
    "\n",
    "\n",
    "# Preprocessing\n",
    "def preprocess_text(text):\n",
    "    text = str(text).lower()\n",
    "    return re.sub(r\"[^a-z0-9\\s]\", \"\", text)\n",
    "\n",
    "\n",
    "def build_search_blob(row, cols):\n",
    "    text = \" \".join(str(row[col]) for col in cols if pd.notnull(row[col]))\n",
    "    text = re.sub(r\"[^a-z0-9\\s]\", \"\", text.lower())\n",
    "    tokens = text.split()\n",
    "\n",
    "    seen = set()\n",
    "    cleaned_tokens = []\n",
    "    for token in tokens:\n",
    "        if token and token not in seen and token not in NOISE_WORDS:\n",
    "            seen.add(token)\n",
    "            cleaned_tokens.append(token)\n",
    "\n",
    "    return \" \".join(cleaned_tokens)\n",
    "\n",
    "\n",
    "# Build search dataset\n",
    "def prepare_dataframe(df, cols):\n",
    "    print(\"Generating search blobs and normalized fields...\")\n",
    "    df[\"search_blob\"] = df.apply(lambda row: build_search_blob(row, cols), axis=1)\n",
    "    df[\"units_traded\"] = df[\"units_traded\"].fillna(0)\n",
    "    df[\"norm_popularity\"] = np.log1p(df[\"units_traded\"]) / np.log1p(\n",
    "        df[\"units_traded\"].max()\n",
    "    )\n",
    "\n",
    "    for col in [\"model_name\", \"brand\", \"search_blob\"]:\n",
    "        df[f\"{col}_normalized\"] = df[col].apply(preprocess_text)\n",
    "\n",
    "    df[\"embedding_input\"] = (\n",
    "        df[\"model_name_normalized\"]\n",
    "        + \" \"\n",
    "        + df[\"brand_normalized\"]\n",
    "        + \" \"\n",
    "        + df[\"search_blob_normalized\"]\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "# Generate embeddings\n",
    "def generate_embeddings(texts, dense_model, batch_size=64):\n",
    "    print(\"Generating dense embeddings...\")\n",
    "    embeddings = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size)):\n",
    "        batch = texts[i : i + batch_size]\n",
    "        batch_embeds = dense_model.encode(batch, normalize_embeddings=True)\n",
    "        embeddings.append(batch_embeds)\n",
    "        del batch_embeds\n",
    "        gc.collect()\n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "\n",
    "# Build FAISS index\n",
    "def build_faiss_index(embedding_matrix):\n",
    "    print(\"Building FAISS index...\")\n",
    "    dim = embedding_matrix.shape[1]\n",
    "    index = faiss.IndexFlatIP(dim)\n",
    "    index.add(embedding_matrix)\n",
    "    return index\n",
    "\n",
    "\n",
    "# Search function\n",
    "def search(query, df, index, dense_model, k=10, K=50):\n",
    "    query_clean = preprocess_text(query)\n",
    "\n",
    "    # If query is empty, return most popular products\n",
    "    if not query_clean.strip():\n",
    "        top_df = df.sort_values(\"norm_popularity\", ascending=False).head(k).copy()\n",
    "        return top_df.reset_index(drop=True)[\n",
    "            [\"model_name\", \"brand\", \"search_blob\", \"units_traded\", \"norm_popularity\"]\n",
    "        ].rename(\n",
    "            columns={\n",
    "                \"model_name\": \"Model\",\n",
    "                \"brand\": \"Brand\",\n",
    "                \"search_blob\": \"Matched Text\",\n",
    "                \"units_traded\": \"Monthly Sales\",\n",
    "                \"norm_popularity\": \"Normalized Popularity\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "    query_embedding = dense_model.encode(query_clean, normalize_embeddings=True)\n",
    "    D, I = index.search(np.array([query_embedding]), k=K)  # noqa: E741\n",
    "    results = []\n",
    "\n",
    "    for idx, vec_score in zip(I[0], D[0]):\n",
    "        row = df.iloc[idx]\n",
    "\n",
    "        fuzzy_model = (\n",
    "            fuzz.token_set_ratio(query_clean, row[\"model_name_normalized\"]) / 100\n",
    "        )\n",
    "        fuzzy_brand = fuzz.token_set_ratio(query_clean, row[\"brand_normalized\"]) / 100\n",
    "        fuzzy_blob = (\n",
    "            fuzz.token_set_ratio(query_clean, row[\"search_blob_normalized\"]) / 100\n",
    "        )\n",
    "        char_sim = SequenceMatcher(\n",
    "            None, query_clean, row[\"model_name_normalized\"]\n",
    "        ).ratio()\n",
    "        exact_boost = (\n",
    "            1.0\n",
    "            if query_clean in row[\"model_name_normalized\"]\n",
    "            else (0.5 if query_clean in row[\"search_blob_normalized\"] else 0.0)\n",
    "        )\n",
    "\n",
    "        hybrid_score = (\n",
    "            0.4 * vec_score\n",
    "            + 0.3 * fuzzy_model\n",
    "            + 0.3 * fuzzy_brand\n",
    "            + 0.2 * fuzzy_blob\n",
    "            + 0.2 * char_sim\n",
    "            + 0.5 * exact_boost\n",
    "            + 0.4 * row[\"norm_popularity\"]\n",
    "        )\n",
    "\n",
    "        results.append(\n",
    "            {\n",
    "                \"Model\": row[\"model_name\"],\n",
    "                \"Brand\": row[\"brand\"],\n",
    "                \"Matched Text\": row[\"search_blob_normalized\"],\n",
    "                \"Model Name\": row[\"model_name_normalized\"],\n",
    "                \"Monthly Sales\": row[\"units_traded\"],\n",
    "                \"FAISS Score\": vec_score,\n",
    "                \"Fuzzy Model\": fuzzy_model,\n",
    "                \"Fuzzy Brand\": fuzzy_brand,\n",
    "                \"Fuzzy Blob\": fuzzy_blob,\n",
    "                \"Model Char Similarity\": char_sim,\n",
    "                \"Exact Boost\": exact_boost,\n",
    "                \"Normalized Popularity\": row[\"norm_popularity\"],\n",
    "                \"Hybrid Score\": hybrid_score,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return (\n",
    "        pd.DataFrame(results)\n",
    "        .sort_values(\"Hybrid Score\", ascending=False)\n",
    "        .reset_index(drop=True)[:k]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e8143f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dense encoder...\n",
      "Generating search blobs and normalized fields...\n",
      "Generating dense embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:13<00:00,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building FAISS index...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load resources\n",
    "dense_model = load_resources()\n",
    "\n",
    "# Define columns used for blob generation\n",
    "cols = [\n",
    "    \"model_name\",\n",
    "    \"primary_category\",\n",
    "    \"secondary_category\",\n",
    "    \"product_type\",\n",
    "    \"product_system\",\n",
    "    \"brand\",\n",
    "    \"family\",\n",
    "]\n",
    "\n",
    "# Prepare data\n",
    "df = prepare_dataframe(df, cols)\n",
    "\n",
    "# Generate embeddings\n",
    "embedding_matrix = generate_embeddings(df[\"embedding_input\"].tolist(), dense_model)\n",
    "\n",
    "# Build FAISS index\n",
    "index = build_faiss_index(embedding_matrix)\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96a4ce7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search function wrapper\n",
    "def search_query(query, k=10):\n",
    "    return search(query, df, index, dense_model, k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c40e2ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f19feb916d894ab1913b3cf1b16919a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='ðŸ” Query:', layout=Layout(width='80%'), placeholder='Search for products...')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54433ed9ea1d4c089b5e074fcc47a934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query_box = widgets.Text(\n",
    "    placeholder=\"Search for products...\",\n",
    "    description=\"ðŸ” Query:\",\n",
    "    layout=widgets.Layout(width=\"80%\"),\n",
    ")\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "\n",
    "def on_query_submit(change):\n",
    "    output.clear_output()\n",
    "    with output:\n",
    "        results = search_query(change[\"new\"])\n",
    "        display(results)\n",
    "\n",
    "\n",
    "# Unregister previous observers to avoid duplicate triggers\n",
    "query_box.unobserve_all()\n",
    "\n",
    "# Register the observer\n",
    "query_box.observe(on_query_submit, names=\"value\")\n",
    "\n",
    "display(query_box, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26196bdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
